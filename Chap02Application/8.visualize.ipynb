{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85b1c2d-c102-4628-bee4-5e4dbe8980f1",
   "metadata": {},
   "source": [
    "# 二、大语言模型的可视化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7744bc-789a-4e7b-8b03-ecdab26dc541",
   "metadata": {},
   "source": [
    "### 1. 使用torchviz可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b5d22-ea75-4a50-850d-1972e51aaca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchviz\n",
    "#!sudo apt install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0798b-5240-4aff-b254-c38e82dc12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"../models/google-bert/bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 模拟输入\n",
    "text = \"Hello, Transformers!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 生成计算图\n",
    "output = model(**inputs)\n",
    "dot = make_dot(output.last_hidden_state, params=dict(model.named_parameters()))\n",
    "dot.render(\"model_structure\", format=\"png\")  # 保存为 PNG 文件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d406fbf-865f-4169-aeeb-506d826e6347",
   "metadata": {},
   "source": [
    "## 2. 使用onnx可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33295e99-8c64-4f17-9ed6-a235ebee81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca382f-a785-46ac-9a4f-36709c4e1f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"../models/google-bert/bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 创建输入\n",
    "inputs = tokenizer(\"Hello, Transformers!\", return_tensors=\"pt\")\n",
    "\n",
    "# 导出 ONNX\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    (inputs[\"input_ids\"],), \n",
    "    \"model.onnx\", \n",
    "    opset_version=14,\n",
    "    input_names=[\"input_ids\"], \n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input_ids\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a6c59-69db-4b5e-9726-282aac070aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://netron.app/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
