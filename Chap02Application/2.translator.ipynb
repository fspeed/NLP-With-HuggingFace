{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85b1c2d-c102-4628-bee4-5e4dbe8980f1",
   "metadata": {},
   "source": [
    "# 二、自然语言处理之模型应用----翻译\n",
    "\n",
    "HuggingFace有一个巨大的模型库，其中一些是已经非常成熟的经典模型，这些模型即使不进行任何训练也能直接得出比较好的预测结果，也就是常说的Zero Shot Learning。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaa7a7c-3f55-4a1a-afe6-de59acfef1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9c604-9033-49c9-ac19-5b2d1ebd7888",
   "metadata": {},
   "source": [
    "## 1. 英译汉\n",
    "\n",
    "使用管道工具处理文本分类任务，代码如下：\n",
    "\n",
    "### 1) 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356ab7d7-cd0e-49e7-9c38-b3fb706091da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 13 files:   0%|                                 | 0/13 [00:00<?, ?it/s]Downloading 'pytorch_model.bin' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/Q1p2l2BzM1m6P5jKvr8WTq1TUio=.69a1d6ec829cee349360b3b677ac0aa99a7d88822d1a6578370029efffdca3f5.incomplete'\n",
      "Downloading 'rust_model.ot' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/ee-WZw9U-e9t7gTGo9Yn82pHA_c=.9863d8dc7fd640182d93454f9a0d0f986aca5da7ffebaae1892fa43413578d15.incomplete'\n",
      "Downloading 'flax_model.msgpack' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/gPcsVCQDYDHk-_n0G9uADl7PXIM=.de82e23a535e25896ebdf433ec2b72706a428fb8e47bb87ef72531426edee8c3.incomplete'\n",
      "Downloading 'metadata.json' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/6DxqzIdjuqb-SOz6KVHBYU3UQEk=.b002d347538a28ef68c8f40020351a2ded80add0.incomplete'\n",
      "Downloading 'config.json' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e2c7882d05248a3e47cfa69f3dc6d5cfd99a3c07.incomplete'\n",
      "Downloading 'generation_config.json' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.f07859fcab98712b231d115475990a962eebc851.incomplete'\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/312M [00:00<?, ?B/s]\u001b[ADownloading '.gitattributes' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.ae8c63daedbd4206d7d40126955d4e6ab1c80f8f.incomplete'\n",
      "\n",
      "\n",
      "rust_model.ot:   0%|                                 | 0.00/578M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:   0%|                            | 0.00/310M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "config.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generation_config.json: 293B [00:00, 188kB/s]A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/generation_config.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metadata.json: 1.48kB [00:00, 2.71MB/s]A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/metadata.json\n",
      "Downloading 'README.md' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.cc6fb518752007783a71d6c62af0c8d5f6523975.incomplete'\n",
      "config.json: 1.40kB [00:00, 2.52kB/s]\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/config.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "README.md: 2.67kB [00:00, 4.67MB/s]A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/README.md\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".gitattributes: 391B [00:00, 145kB/s]A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/.gitattributes\n",
      "Fetching 13 files:   8%|█▉                       | 1/13 [00:02<00:30,  2.52s/it]Downloading 'target.spm' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/h_ERsDJjaLfW4DPqrhWdG_HKjc0=.e19744e15a0f53b209fa40dbdc9e7fc4e96771cd.incomplete'\n",
      "Downloading 'source.spm' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/XG33BUjhXEsozhgi_oOX8t22U7k=.3f695c68a3aeb685ded9a5db0865af02c986bebf.incomplete'\n",
      "Downloading 'tf_model.h5' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/a7eHxRFT3OeMBIFg52k2nfj5m7w=.43941ec7f52f3352a2bc7436fa85d93966f2ad19e6b3ffaa4b0bb97731630e67.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "target.spm:   0%|                                    | 0.00/805k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "source.spm:   0%|                                    | 0.00/806k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'tokenizer_config.json' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.af90e7a4c0e5e8f828e146bdb499c22cef85740e.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:   0%|                                   | 0.00/313M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'vocab.json' to '../models/Helsinki-NLP/opus-mt-en-zh/.cache/huggingface/download/j3m-Hy6QvBddw8RXA1uSWl1AJ0c=.423d3deb0188828da557bb61494bf73e4b86d275.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "target.spm: 100%|█████████████████████████████| 805k/805k [00:01<00:00, 746kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/target.spm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json: 44.0B [00:00, 73.6B/s][A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/tokenizer_config.json\n",
      "\n",
      "\n",
      "\n",
      "flax_model.msgpack:   3%|▋                  | 10.5M/310M [00:02<01:10, 4.22MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "source.spm: 100%|█████████████████████████████| 806k/806k [00:01<00:00, 551kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/source.spm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 122kB [00:00, 156kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:   3%|▋                   | 10.5M/312M [00:03<01:27, 3.43MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 320kB [00:00, 399kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 423kB [00:01, 472kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 881kB [00:01, 1.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 1.17MB [00:01, 1.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 1.62MB [00:01, 1.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/vocab.json\n",
      "\n",
      "\n",
      "\n",
      "flax_model.msgpack:   7%|█▎                 | 21.0M/310M [00:04<00:58, 4.91MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:   7%|█▎                  | 21.0M/312M [00:05<01:12, 4.02MB/s]\u001b[A\n",
      "\n",
      "rust_model.ot:   2%|▍                       | 10.5M/578M [00:05<04:52, 1.94MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  10%|█▉                 | 31.5M/310M [00:05<00:48, 5.74MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:   3%|▊                         | 10.5M/313M [00:04<02:22, 2.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  10%|██                  | 31.5M/312M [00:07<00:59, 4.68MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  14%|██▌                | 41.9M/310M [00:07<00:42, 6.27MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:   4%|▊                       | 21.0M/578M [00:07<03:18, 2.81MB/s]\u001b[A\u001b[A\n",
      "pytorch_model.bin:  13%|██▋                 | 41.9M/312M [00:08<00:49, 5.48MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  17%|███▏               | 52.4M/310M [00:08<00:41, 6.27MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:   7%|█▋                        | 21.0M/313M [00:07<01:34, 3.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  17%|███▎                | 52.4M/312M [00:10<00:45, 5.74MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  20%|███▊               | 62.9M/310M [00:10<00:39, 6.28MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:   5%|█▎                      | 31.5M/578M [00:11<03:00, 3.03MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  10%|██▌                       | 31.5M/313M [00:09<01:15, 3.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  20%|████                | 62.9M/312M [00:11<00:40, 6.23MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  24%|████▍              | 73.4M/310M [00:12<00:41, 5.75MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  13%|███▍                      | 41.9M/313M [00:11<01:03, 4.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  24%|████▋               | 73.4M/312M [00:13<00:41, 5.73MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  27%|█████▏             | 83.9M/310M [00:14<00:35, 6.38MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  17%|████▎                     | 52.4M/313M [00:12<00:54, 4.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  27%|█████▍              | 83.9M/312M [00:15<00:37, 6.08MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  30%|█████▊             | 94.4M/310M [00:15<00:32, 6.62MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:   7%|█▋                      | 41.9M/578M [00:15<03:19, 2.68MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  20%|█████▏                    | 62.9M/313M [00:14<00:46, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  30%|██████              | 94.4M/312M [00:16<00:35, 6.22MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  34%|██████▊             | 105M/310M [00:16<00:30, 6.75MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  23%|██████                    | 73.4M/313M [00:16<00:43, 5.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  37%|███████▍            | 115M/310M [00:18<00:27, 7.17MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  34%|███████              | 105M/312M [00:18<00:32, 6.31MB/s]\u001b[A\n",
      "\n",
      "rust_model.ot:   9%|██▏                     | 52.4M/578M [00:19<03:16, 2.68MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  41%|████████            | 126M/310M [00:19<00:25, 7.26MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  37%|███████▊             | 115M/312M [00:19<00:30, 6.53MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  27%|██████▉                   | 83.9M/313M [00:18<00:41, 5.56MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  44%|████████▊           | 136M/310M [00:20<00:23, 7.34MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  40%|████████▍            | 126M/312M [00:21<00:27, 6.73MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  30%|███████▊                  | 94.4M/313M [00:19<00:38, 5.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  47%|█████████▍          | 147M/310M [00:22<00:22, 7.16MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  44%|█████████▏           | 136M/312M [00:22<00:25, 6.82MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  34%|█████████                  | 105M/313M [00:21<00:37, 5.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  11%|██▌                     | 62.9M/578M [00:23<03:16, 2.62MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  51%|██████████▏         | 157M/310M [00:24<00:21, 6.97MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  47%|█████████▉           | 147M/312M [00:25<00:28, 5.90MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  37%|█████████▉                 | 115M/313M [00:23<00:34, 5.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  54%|██████████▊         | 168M/310M [00:25<00:20, 7.01MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  50%|██████████▌          | 157M/312M [00:26<00:25, 6.00MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  58%|███████████▌        | 178M/310M [00:27<00:18, 7.06MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  40%|██████████▊                | 126M/313M [00:25<00:32, 5.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  13%|███                     | 73.4M/578M [00:27<03:10, 2.65MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  61%|████████████▏       | 189M/310M [00:28<00:17, 7.05MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  54%|███████████▎         | 168M/312M [00:29<00:25, 5.65MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  44%|███████████▊               | 136M/313M [00:27<00:31, 5.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  64%|████████████▊       | 199M/310M [00:29<00:15, 7.15MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  57%|███████████▉         | 178M/312M [00:30<00:23, 5.77MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  47%|████████████▋              | 147M/313M [00:29<00:29, 5.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  68%|█████████████▌      | 210M/310M [00:31<00:14, 7.11MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  15%|███▍                    | 83.9M/578M [00:32<03:18, 2.49MB/s]\u001b[A\u001b[A\n",
      "pytorch_model.bin:  60%|████████████▋        | 189M/312M [00:32<00:21, 5.77MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  50%|█████████████▌             | 157M/313M [00:30<00:26, 5.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  71%|██████████████▏     | 220M/310M [00:32<00:12, 7.33MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  54%|██████████████▍            | 168M/313M [00:32<00:22, 6.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  64%|█████████████▍       | 199M/312M [00:34<00:19, 5.81MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  74%|██████████████▉     | 231M/310M [00:34<00:10, 7.22MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  57%|███████████████▍           | 178M/313M [00:33<00:20, 6.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  78%|███████████████▌    | 241M/310M [00:35<00:09, 7.22MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  67%|██████████████       | 210M/312M [00:36<00:17, 5.91MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  81%|████████████████▏   | 252M/310M [00:37<00:08, 7.00MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  60%|████████████████▎          | 189M/313M [00:35<00:20, 5.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  16%|███▉                    | 94.4M/578M [00:37<03:29, 2.31MB/s]\u001b[A\u001b[A\n",
      "pytorch_model.bin:  71%|██████████████▊      | 220M/312M [00:37<00:15, 5.96MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  85%|████████████████▉   | 262M/310M [00:38<00:06, 7.08MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  64%|█████████████████▏         | 199M/313M [00:37<00:18, 6.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  74%|███████████████▌     | 231M/312M [00:39<00:13, 5.84MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  88%|█████████████████▌  | 273M/310M [00:40<00:05, 6.72MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  67%|██████████████████         | 210M/313M [00:39<00:16, 6.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  91%|██████████████████▎ | 283M/310M [00:41<00:03, 7.18MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  77%|████████████████▏    | 241M/312M [00:42<00:13, 5.14MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  70%|███████████████████        | 220M/313M [00:40<00:14, 6.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  18%|████▌                    | 105M/578M [00:43<03:40, 2.15MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  74%|███████████████████▉       | 231M/313M [00:41<00:11, 6.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  95%|██████████████████▉ | 294M/310M [00:43<00:02, 6.49MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  81%|████████████████▉    | 252M/312M [00:44<00:11, 5.12MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  77%|████████████████████▊      | 241M/313M [00:43<00:10, 7.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack:  98%|███████████████████▌| 304M/310M [00:45<00:00, 6.53MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  84%|█████████████████▋   | 262M/312M [00:46<00:09, 5.12MB/s]\u001b[A\n",
      "\n",
      "\n",
      "flax_model.msgpack: 100%|████████████████████| 310M/310M [00:46<00:00, 6.65MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/flax_model.msgpack\n",
      "Fetching 13 files:  31%|███████▋                 | 4/13 [00:48<01:55, 12.84s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  81%|█████████████████████▋     | 252M/313M [00:44<00:08, 6.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  20%|████▉                    | 115M/578M [00:47<03:22, 2.28MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  84%|██████████████████████▋    | 262M/313M [00:46<00:07, 7.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  87%|██████████████████▎  | 273M/312M [00:49<00:08, 4.72MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  87%|███████████████████████▌   | 273M/313M [00:47<00:05, 7.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  91%|███████████████████  | 283M/312M [00:50<00:05, 5.36MB/s]\u001b[A\n",
      "\n",
      "rust_model.ot:  22%|█████▍                   | 126M/578M [00:50<02:58, 2.53MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  91%|████████████████████████▍  | 283M/313M [00:48<00:03, 7.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin:  94%|███████████████████▊ | 294M/312M [00:51<00:03, 5.66MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  94%|█████████████████████████▎ | 294M/313M [00:50<00:02, 7.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  24%|█████▉                   | 136M/578M [00:53<02:37, 2.80MB/s]\u001b[A\u001b[A\n",
      "pytorch_model.bin:  97%|████████████████████▍| 304M/312M [00:53<00:01, 5.80MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5:  97%|██████████████████████████▎| 304M/313M [00:51<00:01, 7.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model.bin: 100%|█████████████████████| 312M/312M [00:54<00:00, 5.73MB/s]\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/pytorch_model.bin\n",
      "Fetching 13 files:  54%|█████████████▍           | 7/13 [00:56<00:44,  7.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tf_model.h5: 100%|███████████████████████████| 313M/313M [00:52<00:00, 5.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/tf_model.h5\n",
      "\n",
      "\n",
      "rust_model.ot:  25%|██████▎                  | 147M/578M [00:55<02:19, 3.09MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  27%|██████▊                  | 157M/578M [00:58<02:04, 3.38MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  29%|███████▎                 | 168M/578M [01:01<02:05, 3.27MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  31%|███████▋                 | 178M/578M [01:03<01:51, 3.60MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  33%|████████▏                | 189M/578M [01:06<01:42, 3.81MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  34%|████████▌                | 199M/578M [01:08<01:32, 4.10MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  36%|█████████                | 210M/578M [01:10<01:25, 4.31MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  38%|█████████▌               | 220M/578M [01:14<01:36, 3.70MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  40%|█████████▉               | 231M/578M [01:17<01:34, 3.66MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  42%|██████████▍              | 241M/578M [01:20<01:33, 3.62MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  44%|██████████▉              | 252M/578M [01:23<01:29, 3.64MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  45%|███████████▎             | 262M/578M [01:25<01:21, 3.88MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  47%|███████████▊             | 273M/578M [01:27<01:13, 4.15MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  49%|████████████▏            | 283M/578M [01:29<01:09, 4.25MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  51%|████████████▋            | 294M/578M [01:32<01:09, 4.07MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  53%|█████████████▏           | 304M/578M [01:34<01:04, 4.27MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  54%|█████████████▌           | 315M/578M [01:37<01:01, 4.29MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  56%|██████████████           | 325M/578M [01:39<00:57, 4.41MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  58%|██████████████▌          | 336M/578M [01:42<01:00, 4.00MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  60%|██████████████▉          | 346M/578M [01:44<00:53, 4.35MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  62%|███████████████▍         | 357M/578M [01:46<00:49, 4.45MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  63%|███████████████▊         | 367M/578M [01:49<00:50, 4.19MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  65%|████████████████▎        | 377M/578M [01:52<00:52, 3.85MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  67%|████████████████▊        | 388M/578M [01:54<00:45, 4.17MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  69%|█████████████████▏       | 398M/578M [01:57<00:42, 4.25MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  71%|█████████████████▋       | 409M/578M [01:59<00:39, 4.31MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  73%|██████████████████▏      | 419M/578M [02:02<00:37, 4.26MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  74%|██████████████████▌      | 430M/578M [02:04<00:33, 4.41MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  76%|███████████████████      | 440M/578M [02:06<00:30, 4.52MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  78%|███████████████████▍     | 451M/578M [02:08<00:28, 4.42MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  80%|███████████████████▉     | 461M/578M [02:10<00:25, 4.64MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  82%|████████████████████▍    | 472M/578M [02:13<00:23, 4.50MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  83%|████████████████████▊    | 482M/578M [02:16<00:22, 4.25MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  85%|█████████████████████▎   | 493M/578M [02:18<00:19, 4.36MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  87%|█████████████████████▊   | 503M/578M [02:21<00:17, 4.28MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  89%|██████████████████████▏  | 514M/578M [02:23<00:14, 4.49MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  91%|██████████████████████▋  | 524M/578M [02:26<00:12, 4.17MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  92%|███████████████████████  | 535M/578M [02:28<00:09, 4.41MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  94%|███████████████████████▌ | 545M/578M [02:30<00:07, 4.45MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  96%|████████████████████████ | 556M/578M [02:32<00:05, 4.47MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot:  98%|████████████████████████▍| 566M/578M [02:34<00:02, 4.69MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot: 100%|████████████████████████▉| 577M/578M [02:37<00:00, 4.53MB/s]\u001b[A\u001b[A\n",
      "\n",
      "rust_model.ot: 100%|█████████████████████████| 578M/578M [02:37<00:00, 3.68MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../models/Helsinki-NLP/opus-mt-en-zh/rust_model.ot\n",
      "Fetching 13 files: 100%|████████████████████████| 13/13 [02:38<00:00, 12.23s/it]\n",
      "/home/fspeed/HuggingFace/models/Helsinki-NLP/opus-mt-en-zh\n"
     ]
    }
   ],
   "source": [
    "# 下载模型\n",
    "!HF_ENDPOINT=https://hf-mirror.com hf download Helsinki-NLP/opus-mt-en-zh --local-dir ../models/Helsinki-NLP/opus-mt-en-zh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447cd6d-64c6-479a-b4a8-a58c3fd2ee13",
   "metadata": {},
   "source": [
    "### 2) 使用pipeline加载模型\n",
    "\n",
    "使用管道工具时，调用者需要做的只是告诉管道工具要进行的任务类型，管道工具会自动分配合适的模型，直接给出预测结果，如果这个预测结果对于调用者已经可以满足需求，则不再需要再训练。\n",
    "\n",
    "管道工具的API非常简洁，隐藏了大量复杂的底层代码，即使是非专业人员也能轻松使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b78610-fba1-440d-ad98-af4cf0cccee3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 翻译\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m translator = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranslation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../models/Helsinki-NLP/opus-mt-en-zh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HuggingFace/.venv/lib/python3.11/site-packages/transformers/pipelines/__init__.py:1078\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m load_tokenizer:\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m         tokenizer = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HuggingFace/.venv/lib/python3.11/site-packages/transformers/pipelines/__init__.py:1073\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m             tokenizer_kwargs = model_kwargs.copy()\n\u001b[32m   1071\u001b[39m             tokenizer_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), tokenizer_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m         tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtokenizer_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m load_tokenizer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HuggingFace/.venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1164\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1162\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class_py.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1163\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1165\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThis tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1166\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33min order to use this tokenizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1167\u001b[39m             )\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1170\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to build an AutoTokenizer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1171\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mTOKENIZER_MAPPING)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1172\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer."
     ]
    }
   ],
   "source": [
    "# 翻译\n",
    "from transformers import pipeline\n",
    "translator = pipeline(task=\"translation\", \n",
    "                      model=\"../models/Helsinki-NLP/opus-mt-en-zh\",\n",
    "                      device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d25edbe-66fc-4237-8fe5-9c3b909de8ff",
   "metadata": {},
   "source": [
    "### 3) 查看模型的配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e695acc2-8d18-40f9-b952-dc83d85631da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"../models/Helsinki-NLP/opus-mt-en-zh\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"decoder_vocab_size\": 65001,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(translator.model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828e5ce-d7b0-4163-a932-511d954be74d",
   "metadata": {},
   "source": [
    "### 4) 使用模型翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9d5afb-1bf3-4939-a2fc-0384968c7541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sentence=\u001b[33m\"\u001b[39m\u001b[33mHugging Face is a technology company based in New York and Paris\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtranslator\u001b[49m(sentence)\n",
      "\u001b[31mNameError\u001b[39m: name 'translator' is not defined"
     ]
    }
   ],
   "source": [
    "sentence=\"Hugging Face is a technology company based in New York and Paris\"\n",
    "translator(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751912aa-864d-4572-87b7-9db3dcdff354",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "## 2. 汉译英\n",
    "\n",
    "\n",
    "### 你自己试试！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a98c9c-4e38-4086-b9c5-7d724f181762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
