{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85b1c2d-c102-4628-bee4-5e4dbe8980f1",
   "metadata": {},
   "source": [
    "# 二、自然语言处理之模型应用----阅读理解\n",
    "\n",
    "HuggingFace有一个巨大的模型库，其中一些是已经非常成熟的经典模型，这些模型即使不进行任何训练也能直接得出比较好的预测结果，也就是常说的Zero Shot Learning。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e780a2-98f0-45bb-beb8-b4a0c4781205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9c604-9033-49c9-ac19-5b2d1ebd7888",
   "metadata": {},
   "source": [
    "### 1) 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f754cc8a-c4ac-4f6c-a0a9-9c699a1544a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载模型\n",
    "#!HF_ENDPOINT=https://hf-mirror.com hf download distilbert/distilbert-base-cased-distilled-squad --local-dir ../models/distilbert/distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39aa7bf-2035-4abc-ae75-7943dfdb8fd1",
   "metadata": {},
   "source": [
    "### 2) 使用pipeline加载模型\n",
    "\n",
    "使用管道工具时，调用者需要做的只是告诉管道工具要进行的任务类型，管道工具会自动分配合适的模型，直接给出预测结果，如果这个预测结果对于调用者已经可以满足需求，则不再需要再训练。\n",
    "\n",
    "管道工具的API非常简洁，隐藏了大量复杂的底层代码，即使是非专业人员也能轻松使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c0bbae-78dc-4520-b921-7d965981956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# 在线加载模型\n",
    "from transformers import pipeline\n",
    "question_answerer=pipeline(task=\"question-answering\", \n",
    "                           model=\"../models/distilbert/distilbert-base-cased-distilled-squad\",\n",
    "                           device=device) # 目前建议用这个代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81c1cc-074f-42dd-9e71-a63d11b9c669",
   "metadata": {},
   "source": [
    "### 3) 查看模型的配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d8a418-f03c-4181-ab1a-432f1a029879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(question_answerer.model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2632c908-247a-4011-a337-96cdbc9cedfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义一个上下文\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text\n",
    "given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on\n",
    "that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the examples/PyTorch/question-\n",
    "answering/run_squad.py script.\n",
    "\"\"\"\n",
    "\n",
    "# 定义两个问题\n",
    "question1 = \"What is extractive question answering?\"\n",
    "question2 = \"What is a good example of a question answering dataset?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85660008-b0d3-4298-9c5a-707c7a3b62ff",
   "metadata": {},
   "source": [
    "### 5) 使用模型预测¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33390d7e-25e4-4bbe-a6c4-1e5fa9eb19b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6149131655693054, 'start': 34, 'end': 95, 'answer': 'the task of extracting an answer from a text\\ngiven a question'}\n",
      "{'score': 0.517393706504663, 'start': 147, 'end': 160, 'answer': 'SQuAD dataset'}\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=question1, context=context)\n",
    "print(result)\n",
    "\n",
    "result = question_answerer(question=question2, context=context)\n",
    "print(result)\n",
    "\n",
    "# 这里是以字节为单位"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57146a-841a-4cba-9f4a-c004dfb2d84a",
   "metadata": {},
   "source": [
    "### 6) 使用from_pretrained加载本地模型，使用底层一点的函数实现\n",
    "\n",
    "参考这个页面 https://huggingface.co/transformers/v2.11.0/model_doc/distilbert.html\n",
    "\n",
    "和这个页面 https://huggingface.co/distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8bf113-324d-4701-b4e9-dc6c9384d391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 27 the task of extracting an answer from a text given a question\n",
      "44 49 SQuAD dataset\n"
     ]
    }
   ],
   "source": [
    "# 加载本地模型，使用底层一点的函数\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('../models/distilbert/distilbert-base-cased-distilled-squad')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('../models/distilbert/distilbert-base-cased-distilled-squad')\n",
    "\n",
    "# 第一个问题\n",
    "inputs = tokenizer(question1, context, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "answer_start_index = int(torch.argmax(outputs.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(torch.argmax(outputs.end_logits, axis=-1)[0])\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "result = tokenizer.decode(predict_answer_tokens)\n",
    "print(answer_start_index, answer_end_index, result) # 这里是以token为单位\n",
    "\n",
    "# 第二个问题\n",
    "inputs = tokenizer(question2, context, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "answer_start_index = int(torch.argmax(outputs.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(torch.argmax(outputs.end_logits, axis=-1)[0])\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "result = tokenizer.decode(predict_answer_tokens)\n",
    "print(answer_start_index, answer_end_index, result) # 这里是以token为单位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed20285-4814-4216-9d9f-a21154db4e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
